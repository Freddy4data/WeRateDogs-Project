{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d2e975",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Archive - Data Wrangle Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b0993",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The main purpose of this project is to practicalize what has been learnt in the data wrangling section of the Udacity Nanodegree program. The data set which is wrangled is tweet archive of Twitter user `@dog_rates`, also known as `WeRateDogs`. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. This report summarizes all of my data wrangling efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349c390",
   "metadata": {},
   "source": [
    "The tasks contained in this project are:\n",
    "- Data Gathering\n",
    "- Data Assessing\n",
    "- Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c661fdf",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "The data used in this project is derived from three different data set and which were obtained with:\n",
    "- **Twitter archive file:** download this file manually by clicking the following link: twitter_archive_enhanced.csv\n",
    "\n",
    "- **The tweet image predictions**, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file (image_predictions.tsv) is hosted on Udacity's servers and should be downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "- **Twitter API & JSON:** Each tweet's retweet count and favorite (\"like\") count at minimum, and any additional data you find interesting. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. \n",
    "    Each tweet's JSON data should be written to its own line. Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a668793",
   "metadata": {},
   "source": [
    "### Data Assessing\n",
    "After I obtained the three data sets, I went on to assess the data both visually and programmatically.\n",
    "- For the visual assessment, I made use of a spreadsheet software (which was Excel), as viewing with pandas wasn't sufficient for complete visual assessment.\n",
    "- For the programmatic assessment, I made use of pandas using different fuctions and methods ( .info(), .describe(), .value_counts(), .sample() e.t.c)\n",
    "\n",
    "After the assessment, I then worked on giving a concise summary of the issues contained in the data sets and divided these issues into quality and tidiness. Some of these issues are as follows:\n",
    "\n",
    "- erroneous data type for timestamp\n",
    "- some names are parsed erroneously and have either null record or is lowercase\n",
    "- some incorrect rating denominator values\n",
    "- rating should be standardized in a single column since is a single variable  Twitter for iPhone\n",
    "- drop the rating_numerator and rating_denominator column\n",
    "- There are 4 kinds of records in the source column which can be extracted by using the display string portion just before the final \"<\\a>\" and they are: Twitter for iPhone, Vine - Make a Scene, Twitter Web Client, TweetDeck.\n",
    "- Many unnecessary columns especially those with too many null values\n",
    "- timestamp column should be split into month, year and day\n",
    "- Columns floofer, doggo, pupper and puppo in the twiiter archive table should be in one column.\n",
    "- Columns related to breed, dog prediction and confidence level should all be placed in 3 columns\n",
    "- merge all the tables together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb7a66",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "After thorough assessment and having developed the issues contained in the data set, I then worked on finding solutions to all of those issues. Some of these cleaning solutions are as follows:\n",
    "- I had to make copies of each of those dataset to allow for reverting of modifications which was made on the newly created data sets.\n",
    "- I then worked on cleaning the quality issues like changing data types, splitting columns(like splitting the `timestamp` column inorder to view the day, year and month), extracted strings from columns(like in the `source` column), dealt with null values and inaccurate columns.\n",
    "- I also worked on some interesting tidiness issues like creating two columns from existing nine columns(i.e the breed and confidence level columns) as well as merging all the tables to create a master column containing all the necessary information from all the individual tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61308503",
   "metadata": {},
   "source": [
    "### Limitation\n",
    "- I was meant to use the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. I couldn't do all that because of the difficulty in applying to the twitter developers platform so as to enable my access to their API.\n",
    "- So I had to make use of the given `tweet_json.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e7e47",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Data wrangling is the process of cleaning, organizing and transforming raw data into the desired format for analyst to use for prompt decision making. It enables businesses to tackle more complex data in less time, produce more accurate results, and better decision.\n",
    "Some benefits of data wrangling includes:\n",
    "- Data wrangling helps to improve data usability as it converts data into a compatible format for the end system\n",
    "- integrates various types of information and their sources(like databases, web services, files e.t.c)\n",
    "\n",
    "Data wrangling is a must have skill for anybody involved in the world of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
